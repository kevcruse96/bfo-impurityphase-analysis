{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import random\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from material_parser.core.material_parser import MaterialParserBuilder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nitrate_precs', 'bi_fe_ratio', 'separate_hydrolysis', '2_methoxyethanol', 'ethylene_glycol', 'acetic_acid', 'citric_acid', 'acetic_anhydride', 'acetylacetone', 'precursor_concentration', 'pH', 'stirring_time_hr', 'stirring_temp_degC', 'age_days', 'age_temp_degC', 'low_coating_time_sec', 'low_coating_rpm', 'high_coating_time_sec', 'high_coating_rpm', 'dry_time_min', 'dry_degC', 'layer_prebake_time_min', 'layer_prebake_degC', 'layer_annealing_time_min', 'layer_annealing_degC', 'final_prebake_time_min', 'final_prebake_degC', 'final_annealing_time_hr', 'final_annealing_degC', 'air_atm', 'o2_atm', 'n2_atm', 'thin_film_thickness_nm']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('./data/bfo_df_codified_20211123.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# WARNING: EDIT THIS (among other things)\n",
    "df = df.fillna(0)\n",
    "\n",
    "features_df = df.drop(['impurity_code', 'recipe_id'], axis=1)\n",
    "labels = df['impurity_code']\n",
    "\n",
    "feature_list = list(features_df.columns)\n",
    "print(feature_list)\n",
    "features = features_df.to_numpy()\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data:  424\n",
      "number of pure syntheses in oversampled data:  212\n",
      "number of impure syntheses in oversampled data:  212\n"
     ]
    }
   ],
   "source": [
    "# Implement SMOTE (Sythetic Minority Oversampling Technique)\n",
    "X = df.loc[:, df.columns != 'impurity_code']\n",
    "y = df.loc[:, df.columns == 'impurity_code']\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "over_sample = SMOTE(random_state=512)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=512)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X, os_data_y = over_sample.fit_resample(X_train, y_train)\n",
    "\n",
    "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
    "\n",
    "print('length of oversampled data: ', len(os_data_X))\n",
    "print('number of pure syntheses in oversampled data: ', len(os_data_y[os_data_y['impurity_code']==0]))\n",
    "print('number of impure syntheses in oversampled data: ', len(os_data_y[os_data_y['impurity_code']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    test_labels = test_labels + 1\n",
    "    predictions = model.predict(test_features) + 1\n",
    "    errors = abs(predictions - (test_labels))\n",
    "    \n",
    "    #print(predictions)\n",
    "    #print(test_labels)\n",
    "    \n",
    "    tp = np.count_nonzero(predictions + test_labels == 4)\n",
    "    tn = np.count_nonzero(predictions + test_labels == 2)\n",
    "    fp = np.count_nonzero(predictions - test_labels == 1)\n",
    "    fn = np.count_nonzero(predictions - test_labels == -1)\n",
    "    \n",
    "    if tp or fp:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "        \n",
    "    if tp or fn:\n",
    "        recall = tp / (tp + fn)\n",
    "    else:\n",
    "        recall = 0\n",
    "        \n",
    "    if precision or recall:\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    mape = 100*np.mean(errors / (test_labels+1))\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    print('\\n')\n",
    "    print(\"Precision: {:0.2f}%\".format(precision))\n",
    "    print(\"Recall: {:0.2f}%\".format(recall))\n",
    "    print(\"F1 score: {:0.2f}%\".format(f1))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: precursor_concentration Importance: 0.16\n",
      "Variable: bi_fe_ratio          Importance: 0.12\n",
      "Variable: layer_annealing_degC Importance: 0.12\n",
      "Variable: final_annealing_degC Importance: 0.11\n",
      "Variable: stirring_temp_degC   Importance: 0.09\n",
      "Variable: pH                   Importance: 0.08\n",
      "Variable: thin_film_thickness_nm Importance: 0.06\n",
      "Variable: n2_atm               Importance: 0.05\n",
      "Variable: acetic_acid          Importance: 0.03\n",
      "Variable: acetic_anhydride     Importance: 0.03\n",
      "Variable: stirring_time_hr     Importance: 0.03\n",
      "Variable: low_coating_rpm      Importance: 0.03\n",
      "Variable: age_days             Importance: 0.02\n",
      "Variable: layer_prebake_degC   Importance: 0.02\n",
      "Variable: citric_acid          Importance: 0.01\n",
      "Variable: dry_time_min         Importance: 0.01\n",
      "Variable: dry_degC             Importance: 0.01\n",
      "Variable: nitrate_precs        Importance: 0.0\n",
      "Variable: separate_hydrolysis  Importance: 0.0\n",
      "Variable: 2_methoxyethanol     Importance: 0.0\n",
      "Variable: ethylene_glycol      Importance: 0.0\n",
      "Variable: acetylacetone        Importance: 0.0\n",
      "Variable: age_temp_degC        Importance: 0.0\n",
      "Variable: low_coating_time_sec Importance: 0.0\n",
      "Variable: high_coating_time_sec Importance: 0.0\n",
      "Variable: high_coating_rpm     Importance: 0.0\n",
      "Variable: layer_prebake_time_min Importance: 0.0\n",
      "Variable: layer_annealing_time_min Importance: 0.0\n",
      "Variable: final_prebake_time_min Importance: 0.0\n",
      "Variable: final_prebake_degC   Importance: 0.0\n",
      "Variable: final_annealing_time_hr Importance: 0.0\n",
      "Variable: air_atm              Importance: 0.0\n",
      "Variable: o2_atm               Importance: 0.0\n",
      "Base model evaluation:\n",
      "####\n",
      "Model Performance\n",
      "Average error: 0.2130 degrees.\n",
      "Accuracy = 91.20%.\n",
      "\n",
      "\n",
      "Precision: 0.59%\n",
      "Recall: 0.57%\n",
      "F1 score: 0.58%\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.3, random_state=512)\n",
    "#print(train_features)\n",
    "#print(train_labels)\n",
    "tree = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    splitter=\"best\",\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=512,\n",
    "    max_features=None,\n",
    ")\n",
    "tree.fit(train_features, train_labels)\n",
    "\n",
    "#pprint(test_features)\n",
    "\n",
    "\n",
    "\n",
    "# Visualize decision tree\n",
    "\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, class_names = ['pure', 'impure'], rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')\n",
    "\n",
    "importances = list(tree.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "print(\"Base model evaluation:\")\n",
    "print(\"####\")\n",
    "base_accuracy = evaluate(tree, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
